# -*- coding: utf-8 -*-
"""ZDC PS3 Inference.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eP2Fnaxujf2ik_2B0MdYcbpQYYDz6tJr
"""

import pandas as pd
import torch
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from peft import PeftModel

model_path = "/content/drive/MyDrive/Zepto IDC Query Classification/l123-lora-fine-tuned"
tokenizer = AutoTokenizer.from_pretrained(model_path)

base_model = AutoModelForSequenceClassification.from_pretrained("sentence-transformers/all-mpnet-base-v2", num_labels=2)
model = PeftModel.from_pretrained(base_model, model_path)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device).eval()

!pip install faiss-cpu

"""L1

"""

import faiss
import numpy as np

# Load your L1 embeddings (from .npy or memory)
l1_embeddings = np.load("/content/drive/MyDrive/Zepto IDC Query Classification/final embeds/all_l1_embeddings.npy")

# Normalize (FAISS works better with normalized vectors + cosine similarity)
faiss.normalize_L2(l1_embeddings)

# Build FAISS index
index_l1 = faiss.IndexFlatIP(l1_embeddings.shape[1])  # IP = inner product (cosine if normalized)
index_l1.add(l1_embeddings)

# Save the index
faiss.write_index(index_l1, "/content/drive/MyDrive/Zepto IDC Query Classification/final embeds/faiss_l1.index")

print(f"FAISS index built and saved. Total entries: {index_l1.ntotal}")

all_l1_df=pd.read_csv("/content/drive/MyDrive/Zepto IDC Query Classification/final embeds/AllL1.csv")
all_l2_df=pd.read_csv("/content/drive/MyDrive/Zepto IDC Query Classification/final embeds/AllL2.csv")
all_l3_df=pd.read_csv("/content/drive/MyDrive/Zepto IDC Query Classification/final embeds/AllL3.csv")

def embed_query(text, tokenizer, model):
    model.eval()
    with torch.no_grad():
        encoded = tokenizer(
            [text],
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=128
        )
        input_ids = encoded["input_ids"].to(model.device)
        attention_mask = encoded["attention_mask"].to(model.device)

        outputs = model.base_model.base_model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            output_hidden_states=True,
            return_dict=True
        )

        cls_embedding = outputs.last_hidden_state[:, 0, :]  # CLS token
        return cls_embedding.cpu().numpy()

index = faiss.read_index("/content/drive/MyDrive/Zepto IDC Query Classification/final embeds/faiss_l1.index")

def search_l1(query, all_l1_df, tokenizer, model, index_l1, k=10, threshold=0.4):
    input_text = f"L1 {query}"
    embedding = embed_query(input_text, tokenizer, model)
    faiss.normalize_L2(embedding)

    scores, indices = index_l1.search(embedding, k)
    results = []
    for score, idx in zip(scores[0], indices[0]):
      if score < threshold:
            continue
      category = all_l1_df.iloc[idx]["category"]
      product = all_l1_df.iloc[idx]["product_name"]
      results.append((round(score, 4), category, product))
    return results

def search_l1(query, all_l1_df, tokenizer, model, index_l1, k=10, threshold=0.4):
    input_text = f"L1 {query}"
    embedding = embed_query(input_text, tokenizer, model)
    faiss.normalize_L2(embedding)

    scores, indices = index_l1.search(embedding, k)
    results = []
    for score, idx in zip(scores[0], indices[0]):
        if score < threshold:
            continue
        category = all_l1_df.iloc[idx]["category"]
        product = all_l1_df.iloc[idx]["product_name"]
        results.append((round(score, 4), category, product))
    return results

query = "kinderjoy"
top_results = search_l1(query, all_l1_df, tokenizer, model, index_l1, threshold = 0.0)

print(f"\nðŸ” Top L1 categories for: '{query}'\n")
for score, category, product in top_results:
    print(f"[{score}] {category} (product: {product})")

import faiss
import numpy as np

# Load your L1 embeddings (from .npy or memory)
l2_embeddings = np.load("/content/drive/MyDrive/Zepto IDC Query Classification/final embeds/all_l2_embeddings.npy")

# Normalize (FAISS works better with normalized vectors + cosine similarity)
faiss.normalize_L2(l2_embeddings)

# Build FAISS index
index_l2 = faiss.IndexFlatIP(l2_embeddings.shape[1])  # IP = inner product (cosine if normalized)
index_l2.add(l2_embeddings)

# Save the index
faiss.write_index(index_l2, "/content/drive/MyDrive/Zepto IDC Query Classification/final embeds/faiss_l2.index")

print(f"FAISS index built and saved. Total entries: {index_l2.ntotal}")

def search_l2(query, all_l2_df, tokenizer, model, index_l2, k=10, threshold= 0.4):
    input_text = f"L2 {query}"
    embedding = embed_query(input_text, tokenizer, model)
    faiss.normalize_L2(embedding)

    scores, indices = index_l2.search(embedding, k)
    results = []
    for score, idx in zip(scores[0], indices[0]):
      if score < threshold:
            continue
      category = all_l2_df.iloc[idx]["category"]
      product = all_l2_df.iloc[idx]["product_name"]
      results.append((round(score, 4), category, product))
    return results

query = "loreal hair colour 500"
top_results = search_l2(query, all_l2_df, tokenizer, model, index_l2, threshold= 0.40)

print(f"\nðŸ” Top L2 categories for: '{query}'\n")
for score, category, product in top_results:
    print(f"[{score}] {category} (product: {product})")

import faiss
import numpy as np

# Load your L1 embeddings (from .npy or memory)
l3_embeddings = np.load("/content/drive/MyDrive/Zepto IDC Query Classification/final embeds/all_l3_embeddings.npy")

# Normalize (FAISS works better with normalized vectors + cosine similarity)
faiss.normalize_L2(l3_embeddings)

# Build FAISS index
index_l3 = faiss.IndexFlatIP(l3_embeddings.shape[1])  # IP = inner product (cosine if normalized)
index_l3.add(l3_embeddings)

# Save the index
faiss.write_index(index_l3, "/content/drive/MyDrive/Zepto IDC Query Classification/final embeds/faiss_l3.index")

print(f"FAISS index built and saved. Total entries: {index_l3.ntotal}")

def search_l3(query, all_l3_df, tokenizer, model, index_l3, k=10, threshold=0.4):
    input_text = f"L3 {query}"
    embedding = embed_query(input_text, tokenizer, model)
    faiss.normalize_L2(embedding)

    scores, indices = index_l3.search(embedding, k)
    results = []
    for score, idx in zip(scores[0], indices[0]):
      if score < threshold:
            continue
      category = all_l3_df.iloc[idx]["category"]
      product = all_l3_df.iloc[idx]["product_name"]
      results.append((round(score, 4), category, product))
    return results

query = "choki"
top_results = search_l3(query, all_l3_df, tokenizer, model, index_l3, threshold = 0.5)

print(f"\nðŸ” Top L3 categories for: '{query}'\n")
for score, category, product in top_results:
    print(f"[{score}] {category} (product: {product})")

unlabeled_df = pd.read_csv("/content/drive/MyDrive/Zepto IDC Query Classification/Zepto Data Challenge_ Intent prediction - unseen_search_terms.csv")

results_all = []

for query in tqdm(unlabeled_df['search_term'].dropna()):
    l1_result = search_l1(query, all_l1_df, tokenizer, model, index_l1, k=10, threshold = 0.4)
    l2_result = search_l2(query, all_l2_df, tokenizer, model, index_l2, k=10, threshold = 0.4)
    l3_result = search_l3(query, all_l3_df, tokenizer, model, index_l3, k=10, threshold = 0.45)


    top_l1 = list(set(category for _, category, _ in l1_result))
    top_l2 = list(set(category for _, category, _ in l2_result))
    top_l3 = list(set(category for _, category, _ in l3_result))

    results_all.append({
        "query": query,
        "L1_Categories": top_l1,
        "L2_Categories": top_l2,
        "L3_Categories": top_l3
    })

# ---------------------
# Save results
# ---------------------
final_df = pd.DataFrame(results_all)
# final_df.to_csv("/content/drive/MyDrive/Zepto IDC Query Classification/final_preds/final_unlabeled_predictions.csv", index=False)
print("âœ… Done! Predictions saved.")

final_df.to_csv("final_unlabeled_predictions- test 3.csv")

pip install pyspellchecker

from spellchecker import SpellChecker

spell = SpellChecker()

def correct_query(query):
    words = query.split()
    corrected = []
    for w in words:
        if w in spell:
            corrected.append(w)
        else:
            suggestion = spell.correction(w)
            corrected.append(suggestion if suggestion else w)
    return ' '.join(corrected)

import pandas as pd
from spellchecker import SpellChecker

# Load your catalog
catalog_df = pd.read_csv("/content/drive/MyDrive/Zepto IDC Query Classification/Zepto Data Challenge_ Intent prediction - catalog.csv")

# Extract all product names
product_names = catalog_df['product_name'].dropna().astype(str).tolist()

# Tokenize into individual words
custom_words = set()
for name in product_names:
    for word in name.lower().split():
        if word.isalpha():  # remove symbols/numbers
            custom_words.add(word)

print(f"ðŸ§  Collected {len(custom_words)} custom words from catalog.")

spell = SpellChecker()
spell.word_frequency.load_words(custom_words)

with open("custom_vocab.txt", "w") as f:
    for word in sorted(custom_words):
        f.write(word + "\n")

with open("custom_vocab.txt") as f:
    words = [line.strip() for line in f]
    spell.word_frequency.load_words(words)

def correct_query(query):
    words = query.split()
    corrected = []
    for w in words:
        if w in spell:
            corrected.append(w)
        else:
            suggestion = spell.correction(w)
            corrected.append(suggestion if suggestion else w)
    return ' '.join(corrected)

custom_words.update(["relish"])
spell.word_frequency.load_words(custom_words)

print(correct_query("acnesquad"))  # kinderjoy
print(correct_query("amul mlik"))  # amul milk
print(correct_query("moisturiser gel"))     # nivea



results_all = []

for query in tqdm(unlabeled_df['search_term'].dropna()):
    corrected_query = correct_query(query)  # <-- Apply spell correction

    l1_result = search_l1(corrected_query, all_l1_df, tokenizer, model, index_l1, k=10, threshold=0.4)
    l2_result = search_l2(corrected_query, all_l2_df, tokenizer, model, index_l2, k=10, threshold=0.4)
    l3_result = search_l3(corrected_query, all_l3_df, tokenizer, model, index_l3, k=10, threshold=0.35)

    top_l1 = list(set(category for _, category, _ in l1_result))
    top_l2 = list(set(category for _, category, _ in l2_result))
    top_l3 = list(set(category for _, category, _ in l3_result))

    results_all.append({
        "original_query": query,
        "corrected_query": corrected_query,
        "L1_Categories": top_l1,
        "L2_Categories": top_l2,
        "L3_Categories": top_l3
    })

# ---------------------
# Save results
# ---------------------
final_df = pd.DataFrame(results_all)
# final_df.to_csv("/content/drive/MyDrive/Zepto IDC Query Classification/final_preds/final_unlabeled_predictions_corrected.csv", index=False)
# print("âœ… Done! Corrected predictions saved.")

final_df.to_csv("final_unlabeled_predictions- test 5.csv")